{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metrics\n",
    "\n",
    "If a summary captures well the meaning of a body text, then if we use that summary in an information retrieval index to index the documents, we expect to see query results (rankings) similar to the ones in which we rank by whole body text."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "We can use the Spearman Footrule Distance: we perform a query Q and obtain the ranking Kb of documents indexed by body text, and Ks of documents indexed by summary. We compute the distance of Ks from Kb. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spearman_distance_normalized(vec1, vec2):\n",
    "    distance = 0\n",
    "    max_distance = len(vec1) + 1\n",
    "    max_total_distance = max_distance*len(vec1)\n",
    "    for index1, element1 in enumerate(vec1):\n",
    "        for index2, element2 in enumerate(vec2):\n",
    "            if(element1 == element2):\n",
    "                distance += abs(index1-index2)\n",
    "                break\n",
    "            if(index2 == (len(vec2)-1)):\n",
    "                distance += max_distance\n",
    "                \n",
    "    return 1 - distance/max_total_distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "distance: 7\n"
     ]
    }
   ],
   "source": [
    "vec1 = [\"a1\", \"a2\", \"a4\", \"a5\"]\n",
    "vec2 = [\"a2\", \"a1\", \"a4\", \"a3\"]\n",
    "\n",
    "print(f\"distance: {spearman_distance_normalized(vec1, vec2)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data ##\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "HOST = \"http://144.24.201.133:5000\"\n",
    "articles_json = []\n",
    "rows = []\n",
    "\n",
    "for i in tqdm(range(10)):\n",
    "    articles_json = requests.get(f\"{HOST}/allPapers?skip={i*1000}\").json()\n",
    "\n",
    "    for paper in articles_json:\n",
    "        rows.append(\n",
    "            (\n",
    "                paper[\"title\"],\n",
    "                paper[\"body\"],\n",
    "                paper[\"summary\"]\n",
    "            )\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Instanciate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModel, AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained('sentence-transformers/msmarco-MiniLM-L-6-v3')\n",
    "model = AutoModel.from_pretrained('sentence-transformers/msmarco-MiniLM-L-6-v3').cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectorize docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "#Mean Pooling - Take attention mask into account for correct averaging\n",
    "def mean_pooling(model_output, attention_mask):\n",
    "    token_embeddings = model_output[0] #First element of model_output contains all token embeddings\n",
    "    input_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n",
    "    return torch.sum(token_embeddings * input_mask_expanded, 1) / torch.clamp(input_mask_expanded.sum(1), min=1e-9)\n",
    "\n",
    "def embed_sentences(sentences):\n",
    "    #Clean df titles, bodies and summaries:\n",
    "    #chunk[payload] = chunk[payload].apply(clean_text)\n",
    "    # Tokenize sentences\n",
    "    encoded_input = tokenizer(sentences, padding=True, truncation=True, return_tensors='pt').to(\"cuda\")\n",
    "\n",
    "    # Compute token embeddings\n",
    "    with torch.no_grad():\n",
    "        model_output = model(**encoded_input)\n",
    "    \n",
    "    # Perform pooling. In this case, max pooling.\n",
    "    sentence_embeddings = mean_pooling(model_output, encoded_input['attention_mask'])\n",
    "    return sentence_embeddings[0]\n",
    "    # vectors = []\n",
    "\n",
    "    # for doc in tqdm(df[\"body\"].to_list()):\n",
    "    #     vectors.append(model.encode(doc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "body_vectors = []\n",
    "summary_vectors = []\n",
    "for paper in tqdm(rows):\n",
    "    body_vectors.append({\"body\": paper[0], \"embedding\": embed_sentences(paper[1]).cpu().numpy()})\n",
    "    summary_vectors.append({\"body\": paper[0], \"embedding\": embed_sentences(paper[2]).cpu().numpy()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import NearestNeighbors\n",
    "import numpy as np\n",
    "\n",
    "data_bodies = [body_vector[\"embedding\"] for body_vector in body_vectors]\n",
    "data_summaries = [summary_vector[\"embedding\"] for summary_vector in summary_vectors]\n",
    "\n",
    "nbrs_bodies = NearestNeighbors(n_neighbors=100, algorithm='brute', metric=\"cosine\").fit(data_bodies)\n",
    "nbrs_summares = NearestNeighbors(n_neighbors=100, algorithm='brute', metric=\"cosine\").fit(data_summaries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "896\n"
     ]
    }
   ],
   "source": [
    "query = embed_sentences(\"Radiology and machine learning medical application\").cpu().numpy()\n",
    "# print(query)\n",
    "result_bodies = nbrs_bodies.kneighbors([query])\n",
    "result_summaries = nbrs_summares.kneighbors([query])\n",
    "\n",
    "print(spearman_distance(result_bodies[1][0], result_summaries[1][0]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
